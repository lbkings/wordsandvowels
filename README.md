# wordsandvowels

Study Summary: The motivation for this study is understanding perceptual acuity people can listen to/obtain with phonetic knowledge. Specifically, what information is available to a listener in speech and if individuals can maintain the informationand attend to further acoustic variation when vowels are embedded within a word. Given the rise of AI speech to text and voice to text machines (Amazon Alexa, Siri, etc.), we believe examining how acoustics effect speech is imperative to understanding the lack of invariance problem within contexts effects of speech. This was a between-subjects study where individuals either listened to a continuum of vowels or a vowel embedded in a word -- afterward they listened to a continuum of vowels or a word and had to guess what the position of the first vowel continuum or word they heard (tone) was by clicking a button. The dataset consists of all subjects (19), the continuum or word heard (probe), the position of the correct vowel, their guess, and their reaction time to guessing the correct tone. 

Dataset: 
Dependent Variable: the error of what people reproduce, or the deviation between the probe (vowel continuum or vowel in word) and the tone individuals hear. In the dataset this is coded as the position that the individuals chose (UltPosition). The absolute value must be taken because they are perceptually warped, once done we can take the sum of the magnitude of the bias
Independent Variable: the sound of the vowel (vowel continuum) or word -- where the replicated deviation is the difference. Coded as TTPosition = Trial tone position, PTPosition = Probe tone position, and Position = how many positions off the individual was from the tone. 
Primary Input Files: Subjects1to19_SynthVowel.csv and SynthWordsPA_allsubjs.csv. Subjects1to19_SynthVowel.csv contains all the data from the 19 subjects in the vowel continuum condition and the SynthWordsPA_allsubjs.csv contains all the data from the subjects in the vowel in word context condition. These two files will be merged into one as they are the same experiment but two different conditions. They are organized as two files but will be merged into one file called wordsandvowelsspeechcontexteffects.csv. 

